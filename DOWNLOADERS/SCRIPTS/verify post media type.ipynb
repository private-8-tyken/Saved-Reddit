{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71513688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local root: S:\\minds\\Desktop\\Downloader and Reddit System\\DOWNLOADERS\\SCRIPTS\\out\\media_files\n",
      "Bucket: media-archive\n",
      "Endpoint: https://e42006076fb25fd6e73a881a7bbdebd5.r2.cloudflarestorage.com\n",
      "Prefixes: ['Images', 'RedGiphys', 'Gifs', 'Videos']\n",
      "\n",
      "Remote objects counted per prefix:\n",
      "  Images: 614\n",
      "  RedGiphys: 265\n",
      "  Gifs: 63\n",
      "  Videos: 5\n",
      "\n",
      "Local files scanned: 17\n",
      "  Exact matches:      17\n",
      "  Same-stem matches:  0\n",
      "  Missing:            0\n",
      "\n",
      "Per-prefix matches:\n",
      "  Images: exact=17, same_stem=0\n",
      "  RedGiphys: exact=0, same_stem=0\n",
      "  Gifs: exact=0, same_stem=0\n",
      "  Videos: exact=0, same_stem=0\n",
      "\n",
      "CSV written: S:\\minds\\Desktop\\Downloader and Reddit System\\DOWNLOADERS\\SCRIPTS\\out\\r2_audit.csv\n"
     ]
    }
   ],
   "source": [
    "# Jupyter cell: audit local images vs Cloudflare R2 (multi-prefix support)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "# ======== CONFIGURE ME ========\n",
    "LOCAL_IMAGES_ROOT = Path(\"out/media_files\").resolve()   # e.g., Path(\"UNKNOWN - Copy\").resolve()\n",
    "\n",
    "# Prefer Python list here; falls back to env var R2_PREFIXES (comma-separated), then R2_PREFIX.\n",
    "R2_PREFIXES = [\n",
    "    \"Images\",\n",
    "    \"RedGiphys\",\n",
    "    \"Gifs\",\n",
    "    \"Videos\"\n",
    "]\n",
    "if not R2_PREFIXES:\n",
    "    if os.getenv(\"R2_PREFIXES\"):\n",
    "        R2_PREFIXES = [p.strip().strip(\"/\") for p in os.getenv(\"R2_PREFIXES\").split(\",\") if p.strip()]\n",
    "    else:\n",
    "        single = (os.getenv(\"R2_PREFIX\") or \"\").strip().strip(\"/\")\n",
    "        R2_PREFIXES = [single] if single else [\"\"]  # empty string = no prefix (bucket root)\n",
    "\n",
    "# R2 credentials (from environment)\n",
    "R2_ENDPOINT = os.getenv(\"R2_ENDPOINT\")                # e.g., \"https://<accountid>.r2.cloudflarestorage.com\"\n",
    "R2_ACCESS_KEY_ID = os.getenv(\"R2_ACCESS_KEY_ID\")\n",
    "R2_SECRET_ACCESS_KEY = os.getenv(\"R2_SECRET_ACCESS_KEY\")\n",
    "R2_REGION = os.getenv(\"R2_REGION\", \"auto\")\n",
    "R2_BUCKET = os.getenv(\"R2_BUCKET\")                    # required\n",
    "\n",
    "# Output CSV (written next to the local root)\n",
    "OUT_CSV = LOCAL_IMAGES_ROOT.parent / \"r2_audit.csv\"\n",
    "\n",
    "# ======== VALIDATE ========\n",
    "missing = [name for name, val in [\n",
    "    (\"R2_ENDPOINT\", R2_ENDPOINT),\n",
    "    (\"R2_ACCESS_KEY_ID\", R2_ACCESS_KEY_ID),\n",
    "    (\"R2_SECRET_ACCESS_KEY\", R2_SECRET_ACCESS_KEY),\n",
    "    (\"R2_BUCKET\", R2_BUCKET),\n",
    "] if not val]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required env vars: {', '.join(missing)}\")\n",
    "\n",
    "if not LOCAL_IMAGES_ROOT.exists() or not LOCAL_IMAGES_ROOT.is_dir():\n",
    "    raise FileNotFoundError(f\"Local images root not found or not a directory: {LOCAL_IMAGES_ROOT}\")\n",
    "\n",
    "# ======== CONNECT TO R2 (S3-compatible) ========\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=R2_ENDPOINT,\n",
    "    aws_access_key_id=R2_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n",
    "    region_name=R2_REGION,\n",
    "    config=Config(signature_version=\"s3v4\"),\n",
    ")\n",
    "\n",
    "# ======== HELPERS ========\n",
    "def posix_rel(local_path: Path, root: Path) -> str:\n",
    "    \"\"\"Relative path with forward slashes (S3-style).\"\"\"\n",
    "    return local_path.relative_to(root).as_posix()\n",
    "\n",
    "def make_key(prefix: str, rel: str) -> str:\n",
    "    \"\"\"Join normalized prefix with relative path.\"\"\"\n",
    "    prefix = (prefix or \"\").strip().strip(\"/\")\n",
    "    return f\"{prefix}/{rel}\" if prefix else rel\n",
    "\n",
    "def list_remote_objects(bucket: str, prefix: str | None = None):\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    kwargs = {\"Bucket\": bucket}\n",
    "    if prefix:\n",
    "        kwargs[\"Prefix\"] = prefix\n",
    "    by_key = {}\n",
    "    for page in paginator.paginate(**kwargs):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            by_key[obj[\"Key\"]] = obj\n",
    "    return by_key\n",
    "\n",
    "def split_dir_stem_ext(key: str):\n",
    "    \"\"\"Return (dir_path_with_trailing_slash_or_empty, stem, ext_with_dot_or_empty, filename).\"\"\"\n",
    "    if \"/\" in key:\n",
    "        d, fname = key.rsplit(\"/\", 1)\n",
    "        d += \"/\"\n",
    "    else:\n",
    "        d, fname = \"\", key\n",
    "    if \".\" in fname:\n",
    "        st, ex = fname.rsplit(\".\", 1)\n",
    "        return d, st, \".\" + ex.lower(), fname\n",
    "    else:\n",
    "        return d, fname, \"\", fname\n",
    "\n",
    "# ======== PULL REMOTE INDEX FOR ALL PREFIXES ========\n",
    "remote_by_key = {}               # key -> obj\n",
    "by_dir_stem = defaultdict(list)  # (dir, stem) -> list[(key, ext)]\n",
    "prefix_key_counts = Counter()\n",
    "\n",
    "for pref in R2_PREFIXES:\n",
    "    pref_norm = pref.strip().strip(\"/\")\n",
    "    # List only under this prefix (empty -> full bucket)\n",
    "    submap = list_remote_objects(R2_BUCKET, pref_norm if pref_norm else None)\n",
    "    remote_by_key.update(submap)\n",
    "    prefix_key_counts[pref_norm or \"(root)\"] += len(submap)\n",
    "\n",
    "# Build same-stem map once across all keys\n",
    "for key in remote_by_key:\n",
    "    d, st, ex, _ = split_dir_stem_ext(key)\n",
    "    by_dir_stem[(d, st)].append((key, ex))\n",
    "\n",
    "# ======== SCAN LOCAL & MATCH ACROSS PREFIXES ========\n",
    "rows = []\n",
    "totals = Counter()\n",
    "per_prefix_exact = Counter()\n",
    "per_prefix_same_stem = Counter()\n",
    "\n",
    "for local in LOCAL_IMAGES_ROOT.rglob(\"*\"):\n",
    "    if not local.is_file():\n",
    "        continue\n",
    "\n",
    "    local_rel = posix_rel(local, LOCAL_IMAGES_ROOT)       # e.g., \"abc123/01.jpg\"\n",
    "    local_ext = ((\".\" + local.suffix.lower().lstrip(\".\")) if local.suffix else \"\").lower()\n",
    "\n",
    "    all_expected_keys = [ make_key(pref, local_rel) for pref in R2_PREFIXES ]\n",
    "\n",
    "    matched = False\n",
    "    match_type = \"missing\"\n",
    "    matched_prefix = \"\"\n",
    "    matched_key = \"\"\n",
    "    remote_ext = \"\"\n",
    "    same_ext = False\n",
    "    note = \"\"\n",
    "\n",
    "    # 1) Try exact match in the order of prefixes provided\n",
    "    for pref, key in zip(R2_PREFIXES, all_expected_keys):\n",
    "        if key in remote_by_key:\n",
    "            matched = True\n",
    "            match_type = \"exact\"\n",
    "            matched_prefix = pref\n",
    "            matched_key = key\n",
    "            _, _, remote_ext, _ = split_dir_stem_ext(key)\n",
    "            same_ext = (remote_ext == local_ext)\n",
    "            note = \"exact_match\"\n",
    "            totals[\"exact\"] += 1\n",
    "            per_prefix_exact[pref or \"(root)\"] += 1\n",
    "            break\n",
    "\n",
    "    # 2) If no exact match, try same folder + same stem (any extension) per prefix\n",
    "    if not matched:\n",
    "        for pref, key in zip(R2_PREFIXES, all_expected_keys):\n",
    "            parent_dir, stem, _, _ = split_dir_stem_ext(key)\n",
    "            candidates = by_dir_stem.get((parent_dir, stem), [])\n",
    "            if candidates:\n",
    "                # pick the first candidate\n",
    "                alt_key, remote_ext = candidates[0]\n",
    "                matched = True\n",
    "                match_type = \"same_stem\"\n",
    "                matched_prefix = pref\n",
    "                matched_key = alt_key\n",
    "                same_ext = (remote_ext == local_ext)\n",
    "                note = \"found_same_stem_same_ext\" if same_ext else \"found_same_stem_diff_ext\"\n",
    "                totals[\"same_stem\"] += 1\n",
    "                per_prefix_same_stem[pref or \"(root)\"] += 1\n",
    "                break\n",
    "\n",
    "    if not matched:\n",
    "        totals[\"missing\"] += 1\n",
    "        note = \"missing\"\n",
    "\n",
    "    rows.append({\n",
    "        \"local_rel\": local_rel,\n",
    "        \"local_ext\": local_ext or \"\",\n",
    "        \"all_expected_keys\": \" | \".join(all_expected_keys),\n",
    "        \"matched\": matched,\n",
    "        \"match_type\": match_type,          # exact | same_stem | missing\n",
    "        \"matched_prefix\": matched_prefix or \"\",\n",
    "        \"matched_key\": matched_key,\n",
    "        \"remote_ext\": remote_ext or \"\",\n",
    "        \"same_ext\": same_ext,\n",
    "        \"note\": note,\n",
    "    })\n",
    "\n",
    "# ======== WRITE CSV ========\n",
    "header = [\n",
    "    \"local_rel\", \"local_ext\", \"all_expected_keys\",\n",
    "    \"matched\", \"match_type\", \"matched_prefix\", \"matched_key\",\n",
    "    \"remote_ext\", \"same_ext\", \"note\",\n",
    "]\n",
    "with OUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=header)\n",
    "    w.writeheader()\n",
    "    w.writerows(rows)\n",
    "\n",
    "# ======== SUMMARY ========\n",
    "print(f\"Local root: {LOCAL_IMAGES_ROOT}\")\n",
    "print(f\"Bucket: {R2_BUCKET}\")\n",
    "print(f\"Endpoint: {R2_ENDPOINT}\")\n",
    "print(\"Prefixes:\", [p or \"(root)\" for p in R2_PREFIXES])\n",
    "print(\"\\nRemote objects counted per prefix:\")\n",
    "for p in R2_PREFIXES:\n",
    "    print(f\"  {p or '(root)'}: {prefix_key_counts[p or '(root)']}\")\n",
    "\n",
    "total_files = len(rows)\n",
    "print(f\"\\nLocal files scanned: {total_files}\")\n",
    "print(f\"  Exact matches:      {totals['exact']}\")\n",
    "print(f\"  Same-stem matches:  {totals['same_stem']}\")\n",
    "print(f\"  Missing:            {totals['missing']}\")\n",
    "\n",
    "print(\"\\nPer-prefix matches:\")\n",
    "for p in R2_PREFIXES:\n",
    "    key = p or \"(root)\"\n",
    "    print(f\"  {key}: exact={per_prefix_exact[key]}, same_stem={per_prefix_same_stem[key]}\")\n",
    "\n",
    "print(f\"\\nCSV written: {OUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Primary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
