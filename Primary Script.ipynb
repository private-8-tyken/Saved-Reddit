{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import SCRIPTS.jsonDownloader as jd\n",
    "from SCRIPTS.redditLinkRetriever import fetch_saved_post_links, save_links_txt\n",
    "from SCRIPTS.mediaDownloader import download_embedded_media\n",
    "from SCRIPTS.mediaOrganizer import organize_downloads\n",
    "from SCRIPTS.redgifDownloader import process_external\n",
    "from SCRIPTS.cloudflareUploader import upload_media\n",
    "from SCRIPTS.r2_audit import audit_local_vs_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7585e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to avoid making any changes\n",
    "DRY_RUN_MEDIA = False\n",
    "DRY_RUN_ORGANIZE = False\n",
    "DRY_RUN_CLOUDFLARE = False\n",
    "DRY_RUN_FINAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve saved post links for the specified user\n",
    "links = fetch_saved_post_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849fc88",
   "metadata": {},
   "source": [
    "# NEW POST VALIDATION\n",
    "\n",
    "This section validates new posts from reddits saved folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path(\"ordered_posts.csv\")\n",
    "raw_df = pd.read_csv(csv_path)\n",
    "\n",
    "POST_ID_RE = re.compile(r\"/comments/([a-z0-9]+)(?:[/?#]|$)\", re.IGNORECASE)\n",
    "SHORT_RE   = re.compile(r\"redd\\.it/([a-z0-9]+)(?:[/?#]|$)\", re.IGNORECASE)\n",
    "max_order_num = raw_df.order_num.max()\n",
    "\n",
    "def strip_trailing_slash(url: str) -> str:\n",
    "    # remove trailing slashes only at the very end (doesn't touch scheme)\n",
    "    return url.rstrip(\"/\")\n",
    "\n",
    "def extract_post_id(url: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Try to extract a post id from:\n",
    "      - standard permalink: .../comments/<postid>/...\n",
    "      - shortlink: https://redd.it/<postid>\n",
    "    \"\"\"\n",
    "    m = POST_ID_RE.search(url)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    m = SHORT_RE.search(url)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "existing_ids = set(str(x).lower() for x in raw_df.get(\"post_id\", pd.Series([])).dropna())\n",
    "\n",
    "new_rows = []\n",
    "next_order = max_order_num + 1\n",
    "seen_in_batch = set()  # avoid duplicates within this run\n",
    "\n",
    "for raw_link in reversed(links):\n",
    "    link = strip_trailing_slash(raw_link)\n",
    "    post_id = extract_post_id(link)\n",
    "    if not post_id:\n",
    "        continue\n",
    "    pid = post_id.lower()\n",
    "\n",
    "    # Only add if NOT already in CSV and not already queued this batch\n",
    "    if pid in existing_ids or pid in seen_in_batch:\n",
    "        continue\n",
    "\n",
    "    new_rows.append({\n",
    "        \"order_num\": next_order,\n",
    "        \"link\": link,\n",
    "        \"post_id\": post_id,\n",
    "        \"date_added\": datetime.utcnow().isoformat(timespec=\"seconds\"),\n",
    "    })\n",
    "    seen_in_batch.add(pid)\n",
    "    next_order += 1\n",
    "\n",
    "# Preview as a DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deda00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([raw_df, new_df], ignore_index=True)\n",
    "final_df = final_df.sort_values(by=\"order_num\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(jd)\n",
    "\n",
    "jd.configure(\n",
    "    DATA_ROOT=\"Out\",\n",
    "    SKIP_EXISTING=False,\n",
    "    REPORTS_DIR=\"__reports\"\n",
    "    )\n",
    "\n",
    "summary = jd.process_all(new_df[\"link\"].tolist(), show_progress=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e02cf7",
   "metadata": {},
   "source": [
    "# MEDIA DOWNLOADER\n",
    "Reviews the external and media json folders in **Out/**, downloading:\n",
    "- Images\n",
    "- Gifs\n",
    "- Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe27615",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"external\", \"media\"]\n",
    "download_stats = []\n",
    "\n",
    "# point to your inputs/outputs explicitly\n",
    "for mediaType in folders:\n",
    "    download_stats.append(download_embedded_media(\n",
    "        media_json_dir=Path(\"Out/\" + mediaType),   # where your *.json live\n",
    "        media_out_dir=Path(\"Media/media_files\"),  # where downloads should go\n",
    "        write_fail_csv_to=Path(\"__reports/media_report\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \".csv\"),\n",
    "        show_progress=True,\n",
    "    ))\n",
    "\n",
    "download_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86708a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_stats = organize_downloads(\n",
    "    input_dir=\"Media/media_files\",  # where your downloader wrote files\n",
    "    output_dir=\"Media\",             # where Images/, Videos/, Gifs/ live\n",
    "    strategy=\"move\",\n",
    "    conflict=\"rename\",\n",
    "    show_progress=True,\n",
    "    dry_run=DRY_RUN_ORGANIZE,                  # set True to preview\n",
    "    prune_empty_galleries=True,     # remove empty src folders after moving\n",
    ")\n",
    "\n",
    "move_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad8f71",
   "metadata": {},
   "source": [
    "# REDGIF DOWNLOADER\n",
    "\n",
    "Downloads redgifs from external json folder in **Out/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efaa226",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = process_external(\n",
    "    media_json_dir=Path(\"Out/external\"),\n",
    "    media_out_dir=Path(\"Media/RedGiphys\"),\n",
    "    write_fail_csv_to=Path(\"__reports/redgif_report_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \".csv\"),\n",
    "    write_links_csv_to=Path(\"__reports/external_links\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \".csv\"),\n",
    "    show_progress=True,\n",
    "    dry_run=DRY_RUN_MEDIA,\n",
    "    overwrite_downloads=False,\n",
    ")\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf632f",
   "metadata": {},
   "source": [
    "# CLOUDFLARE VERIFICATION & UPLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_output = []\n",
    "uploadsData = []\n",
    "\n",
    "for mediaType in [\"Images\", \"Videos\", \"Gifs\", \"RedGiphys\"]:\n",
    "    try:\n",
    "        result = upload_media(\n",
    "            input_path=Path(\"Media/\" + mediaType + \"/\"),  # folder with your media or galleries\n",
    "            r2_prefix=mediaType,                # one of: Gifs, Images, RedGiphys, Videos\n",
    "            dry_run=DRY_RUN_CLOUDFLARE,                      # True = preview only, False = actually upload\n",
    "            overwrite=False                    # only overwrite existing files if True\n",
    "        )\n",
    "\n",
    "        raw_output.append(result)\n",
    "        uploadsData.extend(result[\"planned\"])\n",
    "        \n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7754cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(uploadsData)\n",
    "pd.set_option('display.max_rows', None)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0144be",
   "metadata": {},
   "source": [
    "# VERIFY UPLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_results = audit_local_vs_r2(\n",
    "    local_root=Path(\"Media/Images\"),          # where your images/galleries are\n",
    "    r2_prefixes=[\"Images\", \"RedGiphys\", \"Gifs\", \"Videos\"],\n",
    "    write_csv_to=Path(\"__reports/r2_audit\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \".csv\"),\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "audit_results[\"totals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d09795",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRY_RUN_FINAL or (\"missing\" in audit_results[\"totals\"].keys()):\n",
    "    print(final_df.head(20))\n",
    "    print(\"Dry run enabled; ordered_posts not changed\")\n",
    "else:\n",
    "    print(\"Updating ordered_posts.csv with new posts...\")\n",
    "    final_df.to_csv(\"ordered_posts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Primary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
